{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "import pycuda.gpuarray as gpuarray\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Petit benchmark\n",
    "\n",
    "Crois-les, ils sont longs à relancer et ça met longtemps\n",
    "\n",
    "Pour vérifier la mémoire utilisée sur la cg, nvidia-smi\n",
    "\n",
    "A priori ElementwiseKernel est bien le plus rapide, en plus la mémoire est mieux gérée qu'en tentant les opérations algébriques directement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycuda.elementwise import ElementwiseKernel\n",
    "\n",
    "error_kernel = ElementwiseKernel(\"const float *x, const float *y, float *z\",\n",
    "                                \"z[i] = (x[i] - y[i])*(x[i] - y[i])\",\n",
    "                                \"error_kernel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn(10000, 1000).astype(np.float32)\n",
    "b = np.random.randn(10000, 1000).astype(np.float32)\n",
    "a_gpu = gpuarray.to_gpu(a)\n",
    "b_gpu = gpuarray.to_gpu(b)\n",
    "diff_matrix = gpuarray.empty_like(a_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.89 ms ± 39.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "((a_gpu - b_gpu)*(a_gpu - b_gpu)) # En plus soucis de mémoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.74 ms ± 2.85 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "error_kernel(a_gpu , b_gpu, diff_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.9 ms ± 297 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "k = (a-b)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.6 ms ± 544 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "k = diff_matrix.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la pénalité pour chaque matrice pour éviter l'overfitting\n",
    "a = np.arange(1,11).astype(np.float32).reshape(5,2)\n",
    "a_gpu = gpuarray.to_gpu(a)\n",
    "b = np.arange(1, 10).reshape(3,3)\n",
    "b_gpu = gpuarray.to_gpu(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_from_template(template, function_name, v=False, **kwargs):\n",
    "    \"\"\"Create from a template the \"\"\"\n",
    "    if v: print(template % kwargs)\n",
    "    mod = SourceModule(template % kwargs)\n",
    "    return mod.get_function(function_name)\n",
    "    \n",
    "\n",
    "\n",
    "column_sum_template = \"\"\"\n",
    "                        __global__ void sumcol (const float *a, float *b)\n",
    "                        {\n",
    "                            const int nlines = %(nlines)s;\n",
    "                            const int ncols = %(ncols)s;\n",
    "                            const int block_start = blockDim.x * (blockIdx.x + gridDim.x * blockIdx.y);\n",
    "                            const int idx_start = threadIdx.x + block_start ;\n",
    "                            float sum = 0;\n",
    "                            for (int idx = idx_start; idx < nlines * ncols; idx += ncols)\n",
    "                                sum += a[idx];\n",
    "                            b[idx_start] = sum;\n",
    "                        }\"\"\"\n",
    "\n",
    "line_sum_template = \"\"\"\n",
    "                        __global__ void sumline (const float *a, float *b)\n",
    "                        {\n",
    "                            const int ncols = %(ncols)s;\n",
    "                            const int block_start = BlockDim.x * (blockIdx.x + gridDim.x * blockIdx.y);\n",
    "                            const int idx_start = (block_start + threadIdx.x) * ncols;\n",
    "                            float sum = 0;\n",
    "                            for (int idx = idx_start; idx < idx_start + ncols; idx++)\n",
    "                                sum += a[idx];\n",
    "                            b[idx_start] = sum;\n",
    "                        }\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsummodfunc = create_from_template(column_sum_template, \"sumcol\", nlines=5, ncols=2, d=\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 25.,  30.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_sum_columns = gpuarray.zeros((1,2), dtype=np.float32)\n",
    "lsummodfunc(a_gpu, out_sum_columns, block=(2,1,1), grid=(2,2))\n",
    "out_sum_columns.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   2.],\n",
       "       [  3.,   4.],\n",
       "       [  5.,   6.],\n",
       "       [  7.,   8.],\n",
       "       [  9.,  10.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_gpu.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(real_matrix, predicted_matrix, l_u, l_v, p, q):\n",
    "    # Faire la matrice des différences au carré,\n",
    "    # Calcule le coût de p\n",
    "    # Calcule celui de q\n",
    "    return (real_matrix - predicted_matrix)**2 + l_u*norm(p) + l_v * norm(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création de la matrice principale\n",
    "\n",
    "On va se concentrer sur un modèle qui fonctionne, donc on crée une matrice où l'on sait qu'il existe une solution.\n",
    "Pour cela, on crée une des matrices originales P_o et Q_o que l'on multiplie.\n",
    "\n",
    "On note que contrairement à une véritable dataset, la matrice sera ici très dense avec chaque cellule contenant une valeur. Dans la vraie vie (Notes sur Netflix, Amazon, etc...), les matrices comprennent énormément de NaNs, qu'on ne retrouvera pas ici\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Générer deux \"vraies\" matrices P et Q, faire le produit\n",
    "p_o = np.random.randn(100, 1000).astype(np.float32) # Generate from uniform(0, 1)\n",
    "q_o = np.random.randn(1000, 100).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On en profite pour faire un benchmark de la vitesse de mutliplication de matrice par numpy et par cuda\n",
    "On remarque d'ailleurs que la différence de facteur augmente au fur et à mesure qu'on augmente la taille de la matrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345 µs ± 27.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.matmul(p_o, q_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                  #include <stdio.h>\n",
      "                  \n",
      "                  __global__ void prodbyline (const float *p, const float *q, float *r)\n",
      "                  {\n",
      "                  const int nq = 100; // number of columns in q\n",
      "                  const int ncom= 1000; // number of lines in q and of column in p\n",
      "                  const int block_start = (blockIdx.x + gridDim.x * blockIdx.y) * blockDim.x; \n",
      "                  const int startp = (threadIdx.x + block_start) * ncom;\n",
      "                  const int startr = (threadIdx.x + block_start) * nq;\n",
      "                  \n",
      "                  for (int linex = 0; linex < nq; linex++)\n",
      "                      {\n",
      "                      int idcell = linex + startr;\n",
      "                      float sumcell = 0;\n",
      "                      for (int idy = linex, idx = startp;\n",
      "                           idx < startp + ncom;\n",
      "                           idy += nq, idx++)\n",
      "                             sumcell += p[idx] * q[idy];\n",
      "                      r[idcell] = sumcell;\n",
      "                      }\n",
      "                  }\n",
      "                  \n"
     ]
    }
   ],
   "source": [
    "p_gpu = gpuarray.to_gpu(p_o)\n",
    "q_gpu = gpuarray.to_gpu(q_o)\n",
    "matmulpq = create_from_template(matmul_template, \"prodbyline\", nq=100, ncom=1000)\n",
    "res = gpuarray.zeros((100, 100), dtype=np.float32)\n",
    "# Slower than the cpu multiplication because of having to constantly go back and forth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "matmulpq(p_gpu, q_gpu, res, block =(128,1,1), grid=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "resmat = res.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = resmat - np.matmul(p_o, q_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00011253,  0.00013733,  0.00018311,  0.00010681, -0.0001297 ,\n",
       "        0.000103  , -0.00011444, -0.00010681, -0.00012207], dtype=float32)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some difference appear, probably because of precision problem\n",
    "np.extract(np.abs(diff) > 1e-4, diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.62939453e-06,  -2.86102295e-06,  -3.43322754e-05,\n",
       "          1.14440918e-05,   5.72204590e-05,   5.72204590e-06,\n",
       "         -1.90734863e-05,   1.90734863e-05,  -4.19616699e-05,\n",
       "          3.81469727e-06],\n",
       "       [ -2.00271606e-05,   7.62939453e-06,   1.90734863e-06,\n",
       "         -4.76837158e-06,   3.81469727e-06,   3.62396240e-05,\n",
       "          0.00000000e+00,   3.81469727e-06,   5.72204590e-06,\n",
       "          3.43322754e-05],\n",
       "       [  1.90734863e-05,   1.81198120e-05,   0.00000000e+00,\n",
       "         -3.81469727e-06,   4.76837158e-06,   5.72204590e-06,\n",
       "          9.53674316e-07,   1.90734863e-06,   0.00000000e+00,\n",
       "         -1.76578760e-05],\n",
       "       [  1.90734863e-06,   1.14440918e-05,  -1.14440918e-05,\n",
       "         -9.53674316e-06,   1.90734863e-05,   2.47955322e-05,\n",
       "          3.81469727e-05,  -2.09808350e-05,  -3.43322754e-05,\n",
       "          1.90734863e-06],\n",
       "       [ -6.19888306e-06,  -3.81469727e-06,   0.00000000e+00,\n",
       "          1.23977661e-05,  -4.76837158e-07,   1.71661377e-05,\n",
       "         -2.86102295e-05,  -1.52587891e-05,   1.14440918e-05,\n",
       "          1.14440918e-05],\n",
       "       [  9.53674316e-06,  -4.19616699e-05,  -1.14440918e-05,\n",
       "         -1.52587891e-05,   1.90734863e-06,  -1.90734863e-06,\n",
       "          2.09808350e-05,  -1.52587891e-05,   1.52587891e-05,\n",
       "          1.90734863e-06],\n",
       "       [  1.38282776e-05,   3.81469727e-06,   1.90734863e-05,\n",
       "          1.14440918e-05,   2.09808350e-05,   1.71661377e-05,\n",
       "          2.86102295e-06,  -1.90734863e-06,  -5.72204590e-06,\n",
       "         -1.90734863e-05],\n",
       "       [ -2.28881836e-05,  -9.53674316e-07,  -7.62939453e-06,\n",
       "         -1.14440918e-05,  -3.81469727e-06,  -1.14440918e-05,\n",
       "         -4.76837158e-06,  -3.91006470e-05,   0.00000000e+00,\n",
       "         -7.62939453e-06],\n",
       "       [  3.43322754e-05,  -7.62939453e-06,  -1.62124634e-05,\n",
       "         -1.14440918e-05,   0.00000000e+00,   2.28881836e-05,\n",
       "          4.76837158e-07,  -1.68085098e-05,   2.58684158e-05,\n",
       "         -1.33514404e-05],\n",
       "       [  0.00000000e+00,   4.19616699e-05,  -1.90734863e-06,\n",
       "         -1.90734863e-05,  -9.53674316e-06,  -1.90734863e-06,\n",
       "         -7.62939453e-06,  -5.72204590e-06,   2.28881836e-05,\n",
       "         -3.81469727e-06]], dtype=float32)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff[:10, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "matmul_template = \"\"\"\n",
    "                  __global__ void prodbyline (const float *p, const float *q, float *r)\n",
    "                  {\n",
    "                  const uint nq = %(nq)s; // number of columns in q\n",
    "                  const uint ncom= %(ncom)s; // number of lines in q and of column in p\n",
    "                  const uint block_start = (blockIdx.x + gridDim.x * blockIdx.y) * blockDim.x; \n",
    "                  const uint startp = (threadIdx.x + block_start) * ncom;\n",
    "                  const uint startr = (threadIdx.x + block_start) * nq;\n",
    "                                \n",
    "                  for (int linex = 0; linex < nq; linex++)\n",
    "                      {\n",
    "                      int idcell = linex + startr;\n",
    "                      float sumcell = 0;\n",
    "                      for (int idy = linex, idx = startp;\n",
    "                           idx < startp + ncom;\n",
    "                           idy += nq, idx++)\n",
    "                             sumcell += p[idx] * q[idy];\n",
    "                      r[idcell] = sumcell;\n",
    "                      }\n",
    "                  }\n",
    "                  \"\"\"\n",
    "\n",
    "matmul = create_from_template(matmul_template, \"prodbyline\", nq=20, ncom=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(-500,500).reshape(20,50).astype(np.float32)/2\n",
    "b = a.T.copy()\n",
    "a_gpu = gpuarray.to_gpu(a)\n",
    "b_gpu = gpuarray.to_gpu(b)\n",
    "\n",
    "trueres = np.matmul(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_mat = gpuarray.empty((20,20), dtype=np.float32)\n",
    "matmul(a_gpu, b_gpu, out_mat, block=(64,1,1), grid=(1,1))\n",
    "trueres - out_mat.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "matmul_t_template = \"\"\"\n",
    "                  #include <stdio.h>\n",
    "                  \n",
    "                  __global__ void prodbyline (const float *p, const float *q, float *r)\n",
    "                  {\n",
    "                  const uint nq = %(nq)s; // number of columns in q\n",
    "                  const uint ncom= %(ncom)s; // number of lines in q and of column in p\n",
    "                  const uint block_start = (blockIdx.x + gridDim.x * blockIdx.y) * blockDim.x; \n",
    "                  const uint startp = (threadIdx.x + block_start) * ncom;\n",
    "                  const uint startr = (threadIdx.x + block_start) * nq;\n",
    "                  \n",
    "                  for (int linex = 0; linex < nq; linex++)\n",
    "                      {\n",
    "                      int idcell = linex + startr;\n",
    "                      float sumcell = 0;\n",
    "                      for (int idy = linex*ncom, idx = startp;\n",
    "                           idx < startp + ncom;\n",
    "                           idy++, idx++)\n",
    "                             sumcell += p[idx] * q[idy];\n",
    "                      r[idcell] = sumcell;\n",
    "                      }\n",
    "                  }\n",
    "                  \"\"\"\n",
    "\n",
    "matmul_t = create_from_template(matmul_t_template, \"prodbyline\", nq=20, ncom=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_matt = gpuarray.zeros((20,20), dtype=np.float32)\n",
    "matmul_t(a_gpu, a_gpu, out_matt, block=(32,1,1), grid=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.04 ms ± 15.5 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit matmul_t(a_gpu, a_gpu, out_matt, block=(64,1,1), grid=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.06 ms ± 47.4 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit matmul(a_gpu, b_gpu, out_mat, block=(64,1,1), grid=(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que faire quand + de lignes que de threads possible ?\n",
    "- Modulo nb total de threads\n",
    "- \"maillage\" en python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilisation du grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridmod = SourceModule(\"\"\"\n",
    "    #include <stdio.h>\n",
    "    \n",
    "    __global__ void reperage (float *a)\n",
    "    {\n",
    "    printf(\"__NEW__\");\n",
    "    const int idx = threadIdx.x + 5*threadIdx.y;\n",
    "    a[0] = idx;\n",
    "    printf(\"Block is (%d, %d), thread is (%d, %d):\\\\n\", blockIdx.x, blockIdx.y, threadIdx.x, threadIdx.y);\n",
    "    }\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tryprint = gridmod.get_function('reperage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tryprint(a_gpu, block=(2,1,1), grid=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   2.,   3.,   4.,   5.],\n",
       "       [  6.,   7.,   8.,   9.,  10.]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_gpu.get() # ??? Seulement executé quand on appelle get ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension d'un block\n",
    "Je ne comprends pas exactement quel est l'intérêt d'écrire un block en plus d'une dimension. Est-ce que la vitesse est meilleure dans certains cas pour (32, 16, 2) que (1024,1,1) ?\n",
    "A tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
