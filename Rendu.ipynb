{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factorisation de matrice (SGD) avec PyCUDA\n",
    "\n",
    "Pour mon projet d'éléments Logiciels de Traitement des Données Massives, je me suis intéressé à [cet article](https://arxiv.org/pdf/1610.05838.pdf) qui traite de l'algorithme de Stochastic Gradient Descent (SGD) pour factoriser des matrices, dans un contexte de calcul distribué.\n",
    "\n",
    "On cherche à factoriser une matrice R (de taille m\\*n) en deux matrices plus petites, P (m\\*k) et Q (k\\*n).\n",
    "\n",
    "Pour résumer en deux mots le principe du SGD, il s'agit de calculer pour une seule cellule de la matrice l'erreur entre la prédiction et la réalité, puis d'updater les poids en fonction de cette erreur. La possibilité de parallélisation découle du fait que si deux cellules de R ne se trouvent ni dans la même ligne ni dans la même colonne, alors l'ajustement des poids découlant de l'une n'influencera pas sur celle de l'autre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "import pycuda.gpuarray as gpuarray\n",
    "import numpy as np\n",
    "\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (15, 9)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "def create_from_template(template, function_name, v=False, **kwargs):\n",
    "    \"\"\"Le code PyCUDA devant être compilé,  il est souvent nécessaire pour chaque module d'avoir les dimensions des objets\n",
    "    utilisés hardcodés. On prend le meilleur de C et python en créant un template qu'on peut formater avant de le compiler.\n",
    "    On évite ainsi d'avoir à créer une fonction trop complexe (en calcul et en programmation) en C.\"\"\"\n",
    "    if v: print(template % kwargs)\n",
    "    mod = SourceModule(template % kwargs)\n",
    "    return mod.get_function(function_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour s'assurer qu'il existe une solution à notre factorisation, on crée deux matrices P* et Q* qu'on multiplie pour obtenir notre matrice R*.\n",
    "\n",
    "La carte graphique que j'ai à disposition n'est pas à proprement parler ajustée pour contenir des données \"massives\". \n",
    "\n",
    "Je compte donc plutôt démontrer l'intérêt d'utiliser la parallélisation offerte par le calcul sur GPU pour ce problème sur un jeu de données artificiel et relativement petit, sachant qu'il serait ensuite possible de l'implémenter sur un jeu de données réels (sous condition d'un meilleur hardware).\n",
    "\n",
    "Il semblerait de plus que l'utilisation du notebook jupyter complique encore plus la tâche (du code lancé en script ne s'exécute pas dans une cellule notebook)... Enfin, si vous tentez d'utiliser printf dans les modules ([exemple](https://wiki.tiker.net/PyCuda/Examples/UsingPrintf)), il est parfois nécessaire d'utiliser la commande `cuda.Context.synchronize()` pour \"débloquer\" la sortie du buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.045"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 100\n",
    "m = 4000\n",
    "n = 5000\n",
    "\n",
    "(k*m+k*n)/(m*n) # Taille des matrices factorisées par rapport à la matrice originale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les floats utilisés en C on 32 bits, on les converti\n",
    "p_o = np.random.randn(m, k).astype(np.float32)\n",
    "q_o = np.random.randn(k, n).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On en profite pour se convaincre du bien fondé d'utiliser du calcul sous GPU, en effectuant la multiplication de la matrice avec PyCUDA. On compare le résultat à une multiplication de matrice classique sous numpy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                  __global__ void prodbyline (const float *p, const float *q, float *r)\n",
      "                  {\n",
      "                  const uint nq = 5000; // number of columns in q\n",
      "                  const uint np = 4000; // number of lines in p\n",
      "                  const uint ncom= 100; // number of lines in q and of column in p\n",
      "                  const uint block_start = (blockIdx.x + gridDim.x * blockIdx.y) * blockDim.x; \n",
      "                  const uint startp = (threadIdx.x + block_start) * ncom;\n",
      "                  const uint startr = (threadIdx.x + block_start) * nq;\n",
      "                                \n",
      "                  for (int linex = 0; linex < nq; linex++)\n",
      "                      {\n",
      "                      int idcell = linex + startr;\n",
      "                      if (idcell >= np*nq)\n",
      "                          break;\n",
      "                      float sumcell = 0;\n",
      "                      for (int idy = linex, idx = startp;\n",
      "                           idx < startp + ncom;\n",
      "                           idy += nq, idx++)\n",
      "                             sumcell += p[idx] * q[idy];\n",
      "                      r[idcell] = sumcell;\n",
      "                      }\n",
      "                  }\n",
      "                  \n"
     ]
    }
   ],
   "source": [
    "multiply_by_line_template = \"\"\"\n",
    "                  __global__ void prodbyline (const float *p, const float *q, float *r)\n",
    "                  {\n",
    "                  const uint nq = %(nq)s; // number of columns in q\n",
    "                  const uint np = %(np)s; // number of lines in p\n",
    "                  const uint ncom= %(ncom)s; // number of lines in q and of column in p\n",
    "                  const uint block_start = (blockIdx.x + gridDim.x * blockIdx.y) * blockDim.x; \n",
    "                  const uint startp = (threadIdx.x + block_start) * ncom;\n",
    "                  const uint startr = (threadIdx.x + block_start) * nq;\n",
    "                                \n",
    "                  for (int linex = 0; linex < nq; linex++)\n",
    "                      {\n",
    "                      int idcell = linex + startr;\n",
    "                      if (idcell >= np*nq)\n",
    "                          break;\n",
    "                      float sumcell = 0;\n",
    "                      for (int idy = linex, idx = startp;\n",
    "                           idx < startp + ncom;\n",
    "                           idy += nq, idx++)\n",
    "                             sumcell += p[idx] * q[idy];\n",
    "                      r[idcell] = sumcell;\n",
    "                      }\n",
    "                  }\n",
    "                  \"\"\"\n",
    "\n",
    "matmul = create_from_template(multiply_by_line_template, \"prodbyline\",\n",
    "                              nq=n, ncom=k, np=m, v=True)\n",
    "\n",
    "# Print le code tel qu'il sera compilé par pyCUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charge les données sur la GPU\n",
    "p_gpu = gpuarray.to_gpu(p_o)\n",
    "q_gpu = gpuarray.to_gpu(q_o)\n",
    "\n",
    "# On affecte les résultats à une matricel\n",
    "res_matrix = gpuarray.zeros((m, n), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matmul(p_gpu, q_gpu, res_matrix, block=(1024, 1, 1), grid=(2,2))\n",
    "res = res_matrix.get()\n",
    "np.abs(res - np.matmul(p_o, q_o)).max() # quelques différences liées à la précision du float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.8 ms ± 4.15 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.matmul(p_o, q_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le magic %timeit a parfois du mal avec SourceModule\n",
    "\n",
    "# On utilise time\n",
    "import time\n",
    "\n",
    "mat_speed = []\n",
    "for i in range(1, 200):\n",
    "    start = time.time()\n",
    "    matmul(p_gpu, q_gpu, res_matrix, block=(512, 1, 1), grid=(1,1))\n",
    "    end = time.time()\n",
    "    mat_speed.append(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.981590270996094e-05, 0.00012111663818359375)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(mat_speed), max(mat_speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... La multiplication de matrice telle qu'on l'a créée s'avère au mieux aussi efficace que la multiplication numpy. Cela est dû principalement aux nombreux aller-retour que l'on doit faire dans la mémoire. \n",
    "\n",
    "L'overhead d'envoyer les commandes au GPU est une autre explication possible de lenteur pour un si petit jeu de données.\n",
    "\n",
    "Il pourrait être possible d'améliorer la performance en cachant par exemple la ligne utilisée pour la multiplication, ou en transposant la matrice Q avant d'effectuer la multiplication. [Voilà un exemple](https://wiki.tiker.net/PyCuda/Examples/MatrixmulTiled) de multiplication de matrice efficace sous PyCUDA.\n",
    "\n",
    "Cela dit, on a toujours le même problème concernant le volume de données qu'on peut utiliser, bien inférieur à la limite de mémoire du GPU. J'utiliserai donc la multiplication numpy pour calculer l'erreur, sachant que cela n'est pas réellement nécessaire avant la fin de l'algorithme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul de la fonction de perte\n",
    "\n",
    "La fonction de perte se définit de la manière suivante:\n",
    "\n",
    "\\begin{equation*}\n",
    "( \\sum_{u,v} r_{uv} - p_uq_v )^2 + \\lambda_p || p_u ||^2 + \\lambda_q ||q_v||^2\n",
    "\\end{equation*}\n",
    "\n",
    "les lambdas étant des constantes de normalisation visant à éviter l'overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycuda.elementwise import ElementwiseKernel\n",
    "\n",
    "# Calcule l'erreur au carré de chaque cellule\n",
    "error_kernel = ElementwiseKernel(\"const float *x, const float *y, float *z\",\n",
    "                                \"z[i] = (x[i] - y[i])*(x[i] - y[i])\",\n",
    "                                \"error_kernel\")\n",
    "\n",
    "# Calcule la somme sur une ligne ou une colonne\n",
    "column_sum_template = \"\"\"\n",
    "                        __global__ void sumcol (const float *a, float *b)\n",
    "                        {\n",
    "                            const int nlines = %(nlines)s;\n",
    "                            const int ncols = %(ncols)s;\n",
    "                            const int block_start = blockDim.x * (blockIdx.x + gridDim.x * blockIdx.y);\n",
    "                            const int idx_start = threadIdx.x + block_start ;\n",
    "                            float sum = 0;\n",
    "                            for (int idx = idx_start; idx < nlines * ncols; idx += ncols)\n",
    "                                sum += a[idx];\n",
    "                            b[idx_start] = sum;\n",
    "                        }\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour calculer les résultats par ligne, on peut par exemple transposer la matrice avant de calculer la somme par colonne, ou faire un nouveau module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_res = np.random.randn(m,n).astype(np.float32)\n",
    "r_res_gpu = gpuarray.to_gpu(random_res)\n",
    "diff_mat = gpuarray.empty_like(res_matrix)\n",
    "a = res_matrix.get()\n",
    "error_kernel(r_res_gpu, res_matrix, diff_mat) # Run the error kernel, output in diff_mat\n",
    "np.abs(diff_mat.get() - (a - random_res)**2).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.36 ms ± 18.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit error_kernel(r_res_gpu, res_matrix, diff_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.3 ms ± 1.29 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit (a - random_res)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voilà un clair avantage à l'utilisation du GPU ! \n",
    "\n",
    "On perd bien sûr une partie de cet avantage lorsqu'il s'agit de récupérer les données depuis la mémoire GPU, mais pour une taille de matrice conséquente on est clairement gagnant.\n",
    "\n",
    "Pour montrer qu'il ne s'agit pas juste d'une question d'utiliser les built-ins ou non, regardons aussi les performances pour sommer les lignes et les colonnes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumcol = create_from_template(column_sum_template, 'sumcol', nlines=k, ncols=n)\n",
    "out_sumcols = gpuarray.empty((1, n), dtype=np.float32) # Output array\n",
    "sumcol(q_gpu, out_sumcols, block=(1024, 1, 1), grid=(4,2))\n",
    "diff_sumcol = out_sumcols.get() - q_o.sum(axis=0)\n",
    "np.abs(diff_sumcol).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.1 µs ± 341 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sumcol(p_gpu, out_sumcols, block=(1024, 1, 1), grid=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184 µs ± 1.9 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit p_o.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On n'a bien sûr pas besoin de passer par la somme des lignes et des colonnes pour calculer la norme euclidienne au carré, qui est probablement celle à laquelle les auteurs font référence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_kernel = ElementwiseKernel(\"const float *a, float *b\",\n",
    "                                 \"b[i] = a[i]*a[i]\",\n",
    "                                 \"square_kernel\")\n",
    "\n",
    "def total_cost(p, q, real_r, predicted_r, lambda_p = 0.03, lambda_q = 0.03):\n",
    "    \"\"\"Calcule la fonction de coût totale.\n",
    "       Les matrices doivent être celles présentes sur le GPU.\n",
    "       La norme utilisée est la norme euclidienne.\"\"\"\n",
    "    if real_r.shape != predicted_r.shape:\n",
    "        raise ValueError(\"Predicted and real R must be the same size\")\n",
    "    # Create the placeholder matrixes\n",
    "    p_squared = gpuarray.empty_like(p) \n",
    "    q_squared = gpuarray.empty_like(q)\n",
    "    error_matrix = gpuarray.empty_like(real_r)\n",
    "    # Square and calculate the error\n",
    "    square_kernel(p, p_squared)\n",
    "    square_kernel(q, q_squared)\n",
    "    error_kernel(real_r, predicted_r, error_matrix)\n",
    "    error = gpuarray.sum(error_matrix)\n",
    "    return error + gpuarray.sum(p_squared) * lambda_p + gpuarray.sum(q_squared) * lambda_q, error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch update\n",
    "\n",
    "Les mécanismes Hogwild! et wavefront-update décrit dans le papier, bien qu'efficaces, sont complexes à mettre en place.\n",
    "\n",
    "J'ai choisi d'imiter le principe du wavefront et de travailler par batch : pour chaque itération, un travailleur se verra affecter une ligne et une colonne pré-déterminée, compare la valeur calculée avec la véritable valeur de la cellule et met à jour les poids de la ligne de P et la colonne de Q correspondante.\n",
    "\n",
    "On note que dans ce cas, il est inutile d'avoir plus de workers que de colonnes (ou de lignes, selon laquelle est la plus grande : dans un jeu de données réel, il y aura probablement plus d'utilisateur, les lignes, que de colonnes, qui seront par exemple les films à noter.\n",
    "\n",
    "Le mécanisme d'update fonctionne de la manière suivante pour chaque travailleur :\n",
    " - Calcul de la prédiction pour la cellule de matrice affectée\n",
    " - Détermination de l'erreur par rapport à la matrice réelle\n",
    " - Ajustement des valeurs des colonnes et lignes correspondantes\n",
    "    \n",
    "J'ai suivi les recommandations de l'article sur l'ajustement des poids, on ajuste donc les poids selon la formule\n",
    "\n",
    "\\begin{align}\n",
    "p_u \\leftarrow \\alpha (err_{u,v}q_v^T - \\lambda_p p_u )\\\\\n",
    "q_v \\leftarrow \\alpha (err_{u,v}p_u^T - \\lambda_q q_v )\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_calculation_template = \"\"\"\n",
    "                        __global__ void batch_update (const long *lines, const long *cols, float *p, float *q, const float *r)\n",
    "                        {\n",
    "                        const uint nq = %(ncols)s;\n",
    "                        const uint ncom = %(ncom)s;\n",
    "                        const float lambda_p = %(lambda_p)s;\n",
    "                        const float lambda_q = %(lambda_q)s;\n",
    "                        const float alpha = %(alpha)s;\n",
    "                        const uint block_start = blockDim.x * (blockIdx.x + gridDim.x * blockIdx.y);\n",
    "                        const uint worker_id = block_start + threadIdx.x;\n",
    "                        const long worker_line = lines[worker_id];\n",
    "                        const long worker_col = cols[worker_id];\n",
    "                        const uint start_p = worker_line * ncom ;\n",
    "                        const uint start_q = worker_col;\n",
    "                        const float adj_p = 1 - alpha * lambda_p;\n",
    "                        const float adj_q = 1 - alpha * lambda_q;\n",
    "                        \n",
    "                        // Calculate the value of the cell\n",
    "                        float pred = 0;\n",
    "                        for (uint idx = start_p, idy = start_q;\n",
    "                             idx < start_p + ncom;\n",
    "                             idy += nq, idx++){\n",
    "                             pred += p[idx] * q[idy];\n",
    "                             }\n",
    "                        // Calculate the error\n",
    "                        const uint r_id = worker_line * nq + worker_col;\n",
    "                        const float err = r[r_id] - pred;\n",
    "                        \n",
    "                        //Adjust the weights\n",
    "                        for (uint idx = start_p, idy = start_q;\n",
    "                             idx < start_p + ncom;\n",
    "                             idy += nq, idx++){\n",
    "                             float placeholder = p[idx]; // Need a placeholder since we use p to adjust q\n",
    "                             p[idx] *= adj_p;\n",
    "                             p[idx] += alpha * err * q[idy];\n",
    "                             q[idy] *= adj_q;\n",
    "                             q[idy] += alpha * err * placeholder;\n",
    "                             }\n",
    "                        }\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_update = create_from_template(batch_calculation_template, \"batch_update\",\n",
    "                                    ncols=n, ncom=k, lambda_p=0.03, lambda_q=0.03, alpha=0.08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en pratique\n",
    "\n",
    "On prend ici des matrices positives pour pouvoir les comparer avec l'algorithme NMF de scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007875"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 30\n",
    "m = 16000\n",
    "n = 5000\n",
    "\n",
    "(k*m+k*n)/(m*n) # Taille des matrices factorisées par rapport à la matrice originale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les floats utilisés en C on 32 bits, on les converti\n",
    "p_o = np.random.rand(m, k).astype(np.float32)\n",
    "q_o = np.random.rand(k, n).astype(np.float32)\n",
    "\n",
    "# Calcul de la matrice R\n",
    "r = np.matmul(p_o, q_o)\n",
    "r_gpu = gpuarray.to_gpu(r)\n",
    "\n",
    "# Initialize the matrixes for the factorization\n",
    "p = np.random.rand(m, k).astype(np.float32)\n",
    "q = np.random.rand(k, n).astype(np.float32)\n",
    "\n",
    "# Put to GPU\n",
    "p_gpu = gpuarray.to_gpu(p)\n",
    "q_gpu = gpuarray.to_gpu(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 10000\n",
    "n_workers = 4096\n",
    "\n",
    "# Prepare the order matrices\n",
    "p_order = np.arange(m)\n",
    "q_order = np.arange(n)\n",
    "\n",
    "# Training and normalization parameters\n",
    "lambda_p = 0.01\n",
    "lambda_q = 0.01\n",
    "alpha = 0.08\n",
    "batch_update = create_from_template(batch_calculation_template, \"batch_update\",\n",
    "                                    ncols=n, ncom=k, lambda_p=lambda_p, \n",
    "                                    lambda_q=lambda_q, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_list = []\n",
    "for i in range(n_iter):\n",
    "    if i % 20 == 0 : # On ne récupère les données du GPU que toutes les 20 itérations\n",
    "        pred = np.matmul(p_gpu.get(), q_gpu.get())\n",
    "        pred_gpu = gpuarray.to_gpu(pred)\n",
    "        cost = total_cost(p_gpu, q_gpu, r_gpu, pred_gpu, lambda_p, lambda_q)\n",
    "        cost_list.append(cost[0].get().item(0))\n",
    "    # Prepare the coordinates each worker will work on\n",
    "    np.random.shuffle(p_order)\n",
    "    np.random.shuffle(q_order)\n",
    "    pgpu_order = gpuarray.to_gpu(p_order[:n_workers])\n",
    "    qgpu_order = gpuarray.to_gpu(q_order[:n_workers])\n",
    "    # Calculate and update the weights\n",
    "    batch_update(pgpu_order, qgpu_order, p_gpu, q_gpu, r_gpu, block=(1024,1,1), grid=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3wAAAIhCAYAAAAVc7i/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmfBJkiRJ0ogy4ZMkSZKkEfUfZlaEtpki9aIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f975e81ca90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(0, n_iter, 20), cost_list)\n",
    "plt.ylabel(\"Cost_function\")\n",
    "plt.xlabel(\"Itérations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il semblerait qu'au moins au niveau de la fonction de coût, notre algorithme converge (environ à la 5000ème itération).\n",
    "\n",
    "Les poids peuvent encore varier au fur et à mesure des itérations mais les matrices factorisées sont de \"qualité\" comparables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fonction de coût: 1129524.500000, erreur de reconstruction: 1127486.250000\n"
     ]
    }
   ],
   "source": [
    "cost = total_cost(p_gpu, q_gpu, r_gpu, pred_gpu,lambda_p=lambda_p, lambda_q=lambda_q)\n",
    "print(\"Fonction de coût: %f, erreur de reconstruction: %f\" % (cost[0].get().item(0), cost[1].get().item(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "# Peut encore s'améliorer avec plus d'itérations, mais c'est déjà très long\n",
    "matrix_factorizer = NMF(n_components=k)\n",
    "p_NMF = matrix_factorizer.fit_transform(r)\n",
    "q_NMF = matrix_factorizer.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fonction de coût: 910570.025689, erreur de reconstruction: 908809.762225\n"
     ]
    }
   ],
   "source": [
    "NMF_err = ((np.matmul(p_NMF, q_NMF) - r)**2).sum()\n",
    "NMF_cost = lambda_p * (p_NMF**2).sum() + lambda_q * (q_NMF**2).sum() + NMF_err\n",
    "print(\"Fonction de coût: %f, erreur de reconstruction: %f\" % (NMF_cost, NMF_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2min 22s ± 9.76 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit matrix_factorizer.fit_transform(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.54 s ± 7.76 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "n_iter = 5000\n",
    "\n",
    "# Initialize the matrixes for the factorization\n",
    "p = np.random.rand(m, k).astype(np.float32)\n",
    "q = np.random.rand(k, n).astype(np.float32)\n",
    "\n",
    "# Put to GPU\n",
    "p_gpu = gpuarray.to_gpu(p)\n",
    "q_gpu = gpuarray.to_gpu(q)\n",
    "\n",
    "for i in range(n_iter):\n",
    "    # Prepare the coordinates each worker will work on\n",
    "    np.random.shuffle(p_order)\n",
    "    np.random.shuffle(q_order)\n",
    "    pgpu_order = gpuarray.to_gpu(p_order[:n_workers])\n",
    "    qgpu_order = gpuarray.to_gpu(q_order[:n_workers])\n",
    "    # Calculate and update the weights\n",
    "    batch_update(pgpu_order, qgpu_order, p_gpu, q_gpu, r_gpu, block=(1024,1,1), grid=(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien sûr, on compare deux algorithmes différents, et j'ai un peu triché, puisque j'ai dû lancer une fois mon algorithme en calculant à chaque fois la fonction de coût pour savoir à partir de combien d'itérations celui-ci converge. Les allers-retours avec le GPU nous fait bien sûr perdre du temps (même si le calcul de la fonction de coût pourrait être améliorié pour ce cas particulier ou on refait la multiplication par le CPU)\n",
    "\n",
    "L'économie de temps réalisée se fait au prix d'une certain perte de précision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Améliorations et prolongements\n",
    "\n",
    "Le premier problème de notre SGD est la précision, comparée à l'algorithme de scikit-learn:\n",
    " - Comme pour la plupart des algorithmes de descente de gradient, l'initialisation des matrices de départ a une certaine importance. [La documentation](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html) scikit-learn nous donne plusieurs idées.\n",
    " - L'erreur est aussi à relativiser (ce n'est pas vraiment une piste d'amélioration). Le SGD nous donne une erreur moyenne d'environ 0.073 par cellule. S'il s'agit d'une note sur 10 (le maximum de r est ici de 15.9), par exemple pour des films, l'accéleration et la scalabilité offertes par la solution du SGD me paraît une raison tout à fait suffisante de la préferer à l'utilisation de scikit-learn.\n",
    "\n",
    "Je sais que l'algorithme est bien sûr encore améliorable, soit en implémentant des suggestions de l'article, ou en améliorant différents points dans la manière dont je l'ai codé:\n",
    "\n",
    " - Limiter les aller-retours avec le GPU:\n",
    "  - Calculer la matrice complète depuis le GPU, cela nous permettrait d'arrêter les itérations si elles n'apportent pas d'amélioration du coût au-delà d'un certain seuil plutôt que de fixer un nombre arbitraire d'itérations.\n",
    "  - Trouver un moyen de déterminer les lignes et colonnes que chaque thread doit traiter depuis le GPU, ie réussir à mélanger les matrices \"d'ordre\" directement sur le GPU.\n",
    "  \n",
    " - Implémenter un algorithme d'update plus complexe: le wavefront semblerait plus simple que le Hogwild!, mais toujours un peu long à coder pour que je puisse l'implémenter ici.\n",
    " \n",
    " - Pour traiter les données réelles : \n",
    "  - Les matrices qu'on factorise dans la vie réelle (je pense toujours par exemple aux notations de films) sont en général très sparse et contiennent des valeurs inconnues. Il faut donc donner des instructions pour qu'un thread qui rencontre un Nan sache quoi faire. Dans le cas de mon algorithme, je pourrais par exemple simplement donner l'instruction de ne rien faire (ce qui ralentirait la convergence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
