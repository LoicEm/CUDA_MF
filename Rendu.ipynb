{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factorisation de matrice (SGD) avec PyCUDA\n",
    "\n",
    "Pour mon projet d'éléments Logiciels de Traitement des Données Massives, je me suis intéressé à [cet article](https://arxiv.org/pdf/1610.05838.pdf) qui traite de l'algorithme de Stochastic Gradient Descent (SGD) pour factoriser des matrices, dans un contexte de calcul distribué.\n",
    "\n",
    "On cherche à factoriser une matrice R (de taille m\\*n) en deux matrices plus petites, P (m\\*k) et Q (k\\*n).\n",
    "\n",
    "Pour résumer en deux mots le principe du SGD, il s'agit de calculer pour une seule cellule de la matrice l'erreur entre la prédiction et la réalité, puis d'updater les poids en fonction de cette erreur. La possibilité de parallélisation découle du fait que si deux cellules de R ne se trouvent ni dans la même ligne ni dans la même colonne, alors l'ajustement des poids découlant de l'une n'influencera pas sur celle de l'autre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "import pycuda.gpuarray as gpuarray\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "def create_from_template(template, function_name, v=False, **kwargs):\n",
    "    \"\"\"Le code PyCUDA devant être compilé,  il est souvent nécessaire pour chaque module d'avoir les dimensions des objets\n",
    "    utilisés hardcodés. On prend le meilleur de C et python en créant un template qu'on peut formater avant de le compiler.\n",
    "    On évite ainsi d'avoir à créer une fonction trop complexe (en calcul et en programmation) en C.\"\"\"\n",
    "    if v: print(template % kwargs)\n",
    "    mod = SourceModule(template % kwargs)\n",
    "    return mod.get_function(function_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour s'assurer qu'il existe une solution à notre factorisation, on crée deux matrices P* et Q* qu'on multiplie pour obtenir notre matrice R*.\n",
    "\n",
    "La carte graphique que j'ai à disposition n'est pas à proprement parler ajustée pour contenir des données \"massives\". \n",
    "\n",
    "Je compte donc plutôt démontrer l'intérêt d'utiliser la parallélisation offerte par le calcul sur GPU pour ce problème sur un jeu de données artificiel et relativement petit, sachant qu'il serait ensuite possible de l'implémenter sur un jeu de données réels (sous condition d'un meilleur hardware).\n",
    "\n",
    "Il semblerait de plus que l'utilisation du notebook jupyter complique encore plus la tâche (du code lancé en script ne s'exécute pas dans une cellule notebook)... Enfin, si vous tentez d'utiliser printf dans les modules ([exemple](https://wiki.tiker.net/PyCuda/Examples/UsingPrintf)), il est parfois nécessaire d'utiliser la commande `cuda.Context.synchronize()` pour \"débloquer\" la sortie du buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.045"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 100\n",
    "m = 4000\n",
    "n = 5000\n",
    "\n",
    "(k*m+k*n)/(m*n) # Taille des matrices factorisées par rapport à la matrice originale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les floats utilisés en C on 32 bits, on les converti\n",
    "p_o = np.random.randn(m, k).astype(np.float32)\n",
    "q_o = np.random.randn(k, n).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On en profite pour se convaincre du bien fondé d'utiliser du calcul sous GPU, en effectuant la multiplication de la matrice avec PyCUDA. On compare le résultat à une multiplication de matrice classique sous numpy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                  __global__ void prodbyline (const float *p, const float *q, float *r)\n",
      "                  {\n",
      "                  const uint nq = 5000; // number of columns in q\n",
      "                  const uint np = 4000; // number of lines in p\n",
      "                  const uint ncom= 100; // number of lines in q and of column in p\n",
      "                  const uint block_start = (blockIdx.x + gridDim.x * blockIdx.y) * blockDim.x; \n",
      "                  const uint startp = (threadIdx.x + block_start) * ncom;\n",
      "                  const uint startr = (threadIdx.x + block_start) * nq;\n",
      "                                \n",
      "                  for (int linex = 0; linex < nq; linex++)\n",
      "                      {\n",
      "                      int idcell = linex + startr;\n",
      "                      if (idcell >= np*nq)\n",
      "                          break;\n",
      "                      float sumcell = 0;\n",
      "                      for (int idy = linex, idx = startp;\n",
      "                           idx < startp + ncom;\n",
      "                           idy += nq, idx++)\n",
      "                             sumcell += p[idx] * q[idy];\n",
      "                      r[idcell] = sumcell;\n",
      "                      }\n",
      "                  }\n",
      "                  \n"
     ]
    }
   ],
   "source": [
    "multiply_by_line_template = \"\"\"\n",
    "                  __global__ void prodbyline (const float *p, const float *q, float *r)\n",
    "                  {\n",
    "                  const uint nq = %(nq)s; // number of columns in q\n",
    "                  const uint np = %(np)s; // number of lines in p\n",
    "                  const uint ncom= %(ncom)s; // number of lines in q and of column in p\n",
    "                  const uint block_start = (blockIdx.x + gridDim.x * blockIdx.y) * blockDim.x; \n",
    "                  const uint startp = (threadIdx.x + block_start) * ncom;\n",
    "                  const uint startr = (threadIdx.x + block_start) * nq;\n",
    "                                \n",
    "                  for (int linex = 0; linex < nq; linex++)\n",
    "                      {\n",
    "                      int idcell = linex + startr;\n",
    "                      if (idcell >= np*nq)\n",
    "                          break;\n",
    "                      float sumcell = 0;\n",
    "                      for (int idy = linex, idx = startp;\n",
    "                           idx < startp + ncom;\n",
    "                           idy += nq, idx++)\n",
    "                             sumcell += p[idx] * q[idy];\n",
    "                      r[idcell] = sumcell;\n",
    "                      }\n",
    "                  }\n",
    "                  \"\"\"\n",
    "\n",
    "matmul = create_from_template(multiply_by_line_template, \"prodbyline\",\n",
    "                              nq=n, ncom=k, np=m, v=True)\n",
    "\n",
    "# Print le code tel qu'il sera compilé par pyCUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charge les données sur la GPU\n",
    "p_gpu = gpuarray.to_gpu(p_o)\n",
    "q_gpu = gpuarray.to_gpu(q_o)\n",
    "\n",
    "# On affecte les résultats à une matricel\n",
    "res_matrix = gpuarray.zeros((m, n), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matmul(p_gpu, q_gpu, res_matrix, block=(1024, 1, 1), grid=(2,2))\n",
    "res = res_matrix.get()\n",
    "np.abs(res - np.matmul(p_o, q_o)).max() # quelques différences liées à la précision du float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.9 ms ± 781 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.matmul(p_o, q_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le magic %timeit a du mal avec SourceModule\n",
    "\n",
    "# On utilise time\n",
    "import time\n",
    "\n",
    "mat_speed = []\n",
    "for i in range(1, 200):\n",
    "    start = time.time()\n",
    "    matmul(p_gpu, q_gpu, res_matrix, block=(512, 1, 1), grid=(1,1))\n",
    "    end = time.time()\n",
    "    mat_speed.append(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.2649765014648438e-05, 0.00016164779663085938)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(mat_speed), max(mat_speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... La multiplication de matrice telle qu'on l'a créée s'avère au mieux aussi efficace que la multiplication numpy. Cela est dû principalement aux nombreux aller-retour que l'on doit faire dans la mémoire. \n",
    "\n",
    "L'overhead d'envoyer les commandes au GPU est une autre explication possible de lenteur pour un si petit jeu de données.\n",
    "\n",
    "Il pourrait être possible d'améliorer la performance en cachant par exemple la ligne utilisée pour la multiplication, ou en transposant la matrice Q avant d'effectuer la multiplication. [Voilà un exemple](https://wiki.tiker.net/PyCuda/Examples/MatrixmulTiled) de multiplication de matrice efficace sous PyCUDA.\n",
    "\n",
    "Cela dit, on a toujours le même problème concernant le volume de données qu'on peut utiliser, bien inférieur à la limite de mémoire du GPU. J'utiliserai donc la multiplication numpy pour calculer l'erreur, sachant que cela n'est pas réellement nécessaire avant la fin de l'algorithme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul de la fonction de perte\n",
    "\n",
    "La fonction de perte se définit de la manière suivante:\n",
    "\n",
    "\\begin{equation*}\n",
    "( \\sum_{u,v} r_{uv} - p_uq_v )^2 + \\lambda_p || p_u ||^2 + \\lambda_q ||q_v||^2\n",
    "\\end{equation*}\n",
    "\n",
    "les lambdas étant des constantes de normalisation visant à éviter l'overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycuda.elementwise import ElementwiseKernel\n",
    "\n",
    "# Calcule l'erreur au carré de chaque cellule\n",
    "error_kernel = ElementwiseKernel(\"const float *x, const float *y, float *z\",\n",
    "                                \"z[i] = (x[i] - y[i])*(x[i] - y[i])\",\n",
    "                                \"error_kernel\")\n",
    "\n",
    "# Calcule la somme sur une ligne ou une colonne\n",
    "column_sum_template = \"\"\"\n",
    "                        __global__ void sumcol (const float *a, float *b)\n",
    "                        {\n",
    "                            const int nlines = %(nlines)s;\n",
    "                            const int ncols = %(ncols)s;\n",
    "                            const int block_start = blockDim.x * (blockIdx.x + gridDim.x * blockIdx.y);\n",
    "                            const int idx_start = threadIdx.x + block_start ;\n",
    "                            float sum = 0;\n",
    "                            for (int idx = idx_start; idx < nlines * ncols; idx += ncols)\n",
    "                                sum += a[idx];\n",
    "                            b[idx_start] = sum;\n",
    "                        }\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour calculer les résultats par ligne, on peut par exemple transposer la matrice avant de calculer la somme par colonne, ou faire un nouveau module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_res = np.random.randn(m,n).astype(np.float32)\n",
    "r_res_gpu = gpuarray.to_gpu(random_res)\n",
    "diff_mat = gpuarray.empty_like(res_matrix)\n",
    "a = res_matrix.get()\n",
    "error_kernel(r_res_gpu, res_matrix, diff_mat) # Run the error kernel, output in diff_mat\n",
    "np.abs(diff_mat.get() - (a - random_res)**2).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.32 ms ± 21.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit error_kernel(r_res_gpu, res_matrix, diff_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.9 ms ± 409 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit (a - random_res)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voilà un clair avantage à l'utilisation du GPU ! \n",
    "\n",
    "On perd bien sûr une partie de cet avantage lorsqu'il s'agit de récupérer les données depuis la mémoire GPU, mais pour une taille de matrice conséquente on est clairement gagnant.\n",
    "\n",
    "Pour montrer qu'il ne s'agit pas juste d'une question d'utiliser les built-ins ou non, regardons aussi les performances pour sommer les lignes et les colonnes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumcol = create_from_template(column_sum_template, 'sumcol', nlines=k, ncols=n)\n",
    "out_sumcols = gpuarray.empty((1, n), dtype=np.float32) # Output array\n",
    "sumcol(q_gpu, out_sumcols, block=(1024, 1, 1), grid=(4,2))\n",
    "diff_sumcol = out_sumcols.get() - q_o.sum(axis=0)\n",
    "np.abs(diff_sumcol).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.7 µs ± 209 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sumcol(p_gpu, out_sumlines, block=(1024, 1, 1), grid=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180 µs ± 757 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit p_o.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On n'a bien sûr pas besoin de passer par la somme des lignes et des colonnes pour calculer la norme euclidienne au carré, qui est probablement celle à laquelle les auteurs font référence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_kernel = ElementwiseKernel(\"const float *a, float *b\",\n",
    "                                 \"b[i] = a[i]*a[i]\",\n",
    "                                 \"square_kernel\")\n",
    "\n",
    "def total_cost(p, q, real_r, predicted_r, lambda_p = 0.03, lambda_q = 0.03):\n",
    "    \"\"\"Calcule la fonction de coût totale.\n",
    "       Les matrices doivent être celles présentes sur le GPU.\n",
    "       La norme utilisée est la norme euclidienne.\"\"\"\n",
    "    if real_r.shape != predicted_r.shape:\n",
    "        raise ValueError(\"Predicted and real R must be the same size\")\n",
    "    # Create the placeholder matrixes\n",
    "    p_squared = gpuarray.empty_like(p) \n",
    "    q_squared = gpuarray.empty_like(q)\n",
    "    error_matrix = gpuarray.empty_like(real_r)\n",
    "    # Square and calculate the error\n",
    "    square_kernel(p, p_squared)\n",
    "    squate_kernel(q, q_squared)\n",
    "    error_kernel(real_r, predicted_r, error_matrix)\n",
    "    return gpuarray.sum(error_kernel) + gpuarray.sum(p_squared) * lambda_p + gpuarray.sum(q_squared) * lambda_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch update\n",
    "\n",
    "Les mécanismes Hogwild! et wavefront-update décrit dans le papier, bien qu'efficaces, sont complexes à mettre en place.\n",
    "\n",
    "J'ai choisi d'imiter le principe du wavefront et de travailler par batch : pour chaque itération, un travailleur se verra affecter une ligne et une colonne pré-déterminée, compare la valeur calculée avec la véritable valeur de la cellule et met à jour les poids de la ligne de P et la colonne de Q correspondante.\n",
    "\n",
    "On note que dans ce cas, il est inutile d'avoir plus de workers que de colonnes (ou de lignes, selon laquelle est la plus grande : dans un jeu de données réel, il y aura probablement plus d'utilisateur, les lignes, que de colonnes, qui seront par exemple les films à noter.\n",
    "\n",
    "Le mécanisme d'update fonctionne de la manière suivante pour chaque travailleur :\n",
    " - Calcul de la prédiction pour la cellule de matrice affectée\n",
    " - Détermination de l'erreur par rapport à la matrice réelle\n",
    " - Ajustement des valeurs des colonnes et lignes correspondantes\n",
    "    \n",
    "J'ai suivi les recommandations de l'article sur l'ajustement des poids, on ajuste donc les poids selon la formule\n",
    "\n",
    "\\begin{align}\n",
    "p_u \\leftarrow \\alpha (err_{u,v}q_v^T - \\lambda_p p_u )\\\\\n",
    "q_v \\leftarrow \\alpha (err_{u,v}p_u^T - \\lambda_q q_v )\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_calculation_template = \"\"\"\n",
    "                        __global__ void batch_update (const float *lines, const float *cols, float *p, float *q, const float *r)\n",
    "                        {\n",
    "                        const int np = %(nlines)s;\n",
    "                        const int nq = %(ncols)s;\n",
    "                        const int ncom = %(ncom)s;\n",
    "                        const float lambda_p = %(lambda_p)s;\n",
    "                        const float lambda_q = %(lambda_q)s;\n",
    "                        const float alpha = %(alpha)s;\n",
    "                        const int block_start = blockDim.x * (blockIdx.x + gridDim.x * blockIdx.y);\n",
    "                        const int worker_id = block_start + threadIdx.x;\n",
    "                        const int worker_line = lines[worker_id];\n",
    "                        const int worker_col = cols[worker_id];\n",
    "                        const int start_p = worker_line * ncom ;\n",
    "                        const int start_q = worker_col;\n",
    "                        \n",
    "                        // Calculate the value of the cell\n",
    "                        int pred = 0;\n",
    "                        for (int idx = start_p, idy = start_q;\n",
    "                             idx < start_p + ncom;\n",
    "                             idy += nq, idx++)\n",
    "                             pred += p[idx] * q[idy];\n",
    "        \n",
    "                        // Calculate the error\n",
    "                        const int r_id = worker_line * nq + worker_col;\n",
    "                        const float err = r[r_id] - pred;\n",
    "                        \n",
    "                        //Adjust the weights\n",
    "                        for (int idx = start_p, idy = start_q;\n",
    "                             idx < start_p + ncom;\n",
    "                             idy += nq, idx++){\n",
    "                             float placeholder = p[idx]; // Need a placeholder since we use p to adjust q\n",
    "                             p[idx] *= (1 - alpha * lambda_p);\n",
    "                             p[idx] += alpha * err * q[idy];\n",
    "                             q[idy] *= (1 - alpha * lambda_q);\n",
    "                             q[idy] += alpha * err * placeholder;\n",
    "                             }\n",
    "                        }\"\"\"\n",
    "\n",
    "batch_update = create_from_template(batch_calculation_template, \"batch_update\", \n",
    "                                    nlines=m, ncols=n, ncom=k, lambda_p=0.03, lambda_q=0.03, alpha=0.08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en pratique\n",
    "\n",
    "On prend ici des matrices positives pour pouvoir les comparer avec l'algorithme NMF de scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 10000\n",
    "n_workers = 2048\n",
    "\n",
    "p_order = np.arange(m)\n",
    "q_order = np.arange(n)\n",
    "\n",
    "# Training and normalization parameters\n",
    "lambda_p = 0.03\n",
    "lambda_q = 0.03\n",
    "alpha = 0.08\n",
    "cost_list = []\n",
    "\n",
    "for i in range(n_iter):\n",
    "    # Prepare the coordinates each worker will work on\n",
    "    np.random.shuffle(p_order)\n",
    "    np.random.shuffle(q_order)\n",
    "    pgpu_order = gpuarray.to_gpu(p_order[:n_workers])\n",
    "    qgpu_order = gpuarray.to_gpu(q_order[:n_workers])\n",
    "    batch_update(pgpu_order, qgpu_order, p_gpu, q_gpu, res_matrix, block=(,), grid=(,))\n",
    "    if i % 100 == 0:\n",
    "        calculate_whole_matrix\n",
    "        total_cost\n",
    "        cost_list.append(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison avec un algorithme de scikit learn\n",
    "%timeit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prolongements et améliorations\n",
    "\n",
    " - Limiter les aller-retours avec le GPU:\n",
    "  - Calculer la matrice complète depuis le GPU\n",
    "  - Trouver un moyen de faire le shuffle des ordres depuis le GPU\n",
    " - Implémenter un algorithme d'update plus complexe.\n",
    " - Suivre d'autres recommandations de l'article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
